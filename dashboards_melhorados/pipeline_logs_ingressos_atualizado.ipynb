# ================================================
# pipeline_logs_ingressos_ajustado.py
# ================================================
#
# Vers√£o completa do pipeline de logs de ingressos,
# ajustada para resgatar 'nome_evento' da tabela ingressos
# e gerar Excel + gr√°ficos como antes.

import sqlite3
import pandas as pd
import plotly.express as px
from sklearn.ensemble import IsolationForest

def carregar_dados_ingressos_com_ia():
    """
    1) Conecta ao banco e l√™ todos os logs de compra de ingressos.
    2) Extrai o ingresso_id da string 'Compra do ingresso ID X'.
    3) Faz merge com a tabela 'ingressos' para resgatar o nome real do evento.
    4) Agrupa para criar features, treina IsolationForest, rotula cada compra como 'Normal' ou 'An√¥malo'.
    5) Retorna o DataFrame final, pronto para gerar Excel e gr√°ficos.
    """

    # ---------------------------------------------------------
    # 1) Conectar ao banco e ler apenas os registros de log que cont√™m 'Compra do ingresso ID'
    # ---------------------------------------------------------
    # Se voc√™ estiver executando a partir da pasta "dashboards_melhorados",
    # use "../database.db". Caso contr√°rio, ajuste para "database.db".
    conn = sqlite3.connect("../database.db")
    query = """
        SELECT 
            u.id           AS usuario_id,
            u.nome         AS nome,
            u.email        AS email,
            l.acao_usuario AS acao,
            l.data_hora
        FROM logs l
        JOIN usuarios u ON u.id = l.usuario_id
        WHERE l.acao_usuario LIKE 'Compra do ingresso ID%'
    """
    df = pd.read_sql_query(query, conn)
    conn.close()

    # ---------------------------------------------------------
    # 2) Converter data_hora para datetime
    # ---------------------------------------------------------
    df['data_hora'] = pd.to_datetime(df['data_hora'])

    # ---------------------------------------------------------
    # 3) Extrair o ID num√©rico do ingresso (a partir da string "Compra do ingresso ID X")
    # ---------------------------------------------------------
    df['ingresso_id'] = (
        df['acao']
        .str.replace("Compra do ingresso ID ", "")  # remove o prefixo textual
        .astype(int)                                # converte pra inteiro
    )

    # ---------------------------------------------------------
    # 4) Carregar a tabela de 'ingressos' para obter o nome real de cada evento
    # ---------------------------------------------------------
    conn2 = sqlite3.connect("../database.db")
    df_ingressos = pd.read_sql_query(
        "SELECT id AS ingresso_id, nome_evento FROM ingressos", conn2
    )
    conn2.close()

    # ---------------------------------------------------------
    # 5) Fazer o merge para trazer a coluna 'nome_evento' para o DataFrame de logs
    # ---------------------------------------------------------
    df = df.merge(df_ingressos, on='ingresso_id', how='left')

    # 6) Copiar 'nome_evento' para uma nova coluna 'evento_real'
    df['evento_real'] = df['nome_evento']

    # 7) Criar coluna 'data' apenas com a data (sem hora) para poss√≠veis agrupamentos
    df['data'] = df['data_hora'].dt.date

    # ---------------------------------------------------------
    # 8) Construir as features que alimentam o IsolationForest
    #    (neste exemplo, usamos apenas 'usuario_id' como feature,
    #     mas voc√™ pode adicionar mais colunas se quiser)
    # ---------------------------------------------------------
    X = df[['usuario_id']]
    iso = IsolationForest(contamination=0.05, random_state=42)
    df['classificacao'] = iso.fit_predict(X)
    # Mapeamos  1  -> 'Normal'   |   -1  ->  'An√¥malo'
    df['classificacao'] = df['classificacao'].map({1: 'Normal', -1: 'An√¥malo'})

    return df


def gerar_excel_e_graficos(df):
    """
    Recebe o DataFrame j√° processado (com 'evento_real' e 'classificacao')
    ‚Üí Gera um arquivo Excel "compras_ingressos_ia.xlsx" com todas as colunas
    ‚Üí Exibe/gera 4 gr√°ficos id√™nticos aos do seu pipeline original:
      1) Compras por Evento (nome real)
      2) Compras por Usu√°rio (com classifica√ß√£o IA)
      3) Evolu√ß√£o por Data
      4) Distribui√ß√£o das Classifica√ß√µes (IA)
    """

    # ---------------------------------------------------------
    # 1) Tentar salvar como Excel
    # ---------------------------------------------------------
    try:
        df.to_excel("compras_ingressos_ia.xlsx", index=False)
        print("üìÅ Arquivo Excel 'compras_ingressos_ia.xlsx' gerado com sucesso.")
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao gerar Excel: {e}")

    # ---------------------------------------------------------
    # 2) Gr√°fico 1: üé´ Compras por Evento
    # ---------------------------------------------------------
    evento_count = df['evento_real'].value_counts().reset_index()
    evento_count.columns = ['Evento', 'Quantidade']
    fig1 = px.bar(
        evento_count,
        x='Evento',
        y='Quantidade',
        title='üé´ Compras por Evento',
        labels={'Evento': 'Evento', 'Quantidade': 'Quantidade'}
    )
    fig1.show()

    # ---------------------------------------------------------
    # 3) Gr√°fico 2: üë§ Compras por Usu√°rio (com Classifica√ß√£o)
    # ---------------------------------------------------------
    user_count = (
        df.groupby(['nome', 'classificacao'])['evento_real']
        .count()
        .reset_index(name='Compras')
    )
    fig2 = px.bar(
        user_count,
        x='nome',
        y='Compras',
        color='classificacao',
        title='üë§ Compras por Usu√°rio (com Classifica√ß√£o IA)',
        labels={'nome': 'Nome do Usu√°rio', 'Compras': 'Quantidade de Compras', 'classificacao': 'Classifica√ß√£o'}
    )
    fig2.show()

    # ---------------------------------------------------------
    # 4) Gr√°fico 3: üìÖ Evolu√ß√£o por Data
    # ---------------------------------------------------------
    data_count = df['data'].value_counts().sort_index().reset_index()
    data_count.columns = ['Data', 'Quantidade']
    # Converter a coluna 'Data' de volta para string no formato dd/mm/aaaa
    data_count['Data'] = data_count['Data'].apply(lambda d: d.strftime('%d/%m/%Y'))
    fig3 = px.line(
        data_count,
        x='Data',
        y='Quantidade',
        markers=True,
        title='üìÜ Compras por Data',
        labels={'Data': 'Data', 'Quantidade': 'Quantidade'}
    )
    fig3.show()

    # ---------------------------------------------------------
    # 5) Gr√°fico 4: ü•ß Distribui√ß√£o das Classifica√ß√µes (IA)
    # ---------------------------------------------------------
    class_count = df['classificacao'].value_counts().reset_index()
    class_count.columns = ['Classifica√ß√£o', 'Quantidade']
    fig4 = px.pie(
        class_count,
        names='Classifica√ß√£o',
        values='Quantidade',
        title='ü•ß Distribui√ß√£o das Classifica√ß√µes (IA)'
    )
    fig4.show()


def executar_pipeline():
    """
    1) Chama carregar_dados_ingressos_com_ia()
    2) Chama gerar_excel_e_graficos(df)
    3) Exibe no console um resumo final
    """
    # ‚Üí Carrega e processa os dados (merge + classifica√ß√£o IA)
    df = carregar_dados_ingressos_com_ia()

    # ‚Üí Gera o Excel e exibe os 4 gr√°ficos (Plotly)
    gerar_excel_e_graficos(df)

    # ‚Üí Mensagem final e resumo de usu√°rios classificados
    print("\n‚úÖ Pipeline finalizada com sucesso!")
    print("Usu√°rios (√∫nicos) e suas classifica√ß√µes:")
    print(df[['usuario_id', 'nome', 'classificacao']].drop_duplicates().reset_index(drop=True))


# ‚ñ∂Ô∏è Se for executado diretamente como script, dispara o pipeline completo
if __name__ == "__main__":
    executar_pipeline()
